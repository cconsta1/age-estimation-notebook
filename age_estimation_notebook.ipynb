{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cconsta1/age-estimation-notebook/blob/main/age_estimation_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrEgy_QP-aA7"
      },
      "source": [
        "# **Install necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL7XGyB0AvFs"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-optimize git+https://github.com/hyperopt/hyperopt-sklearn.git  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary libraries**"
      ],
      "metadata": {
        "id": "mIhIwe_uspY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BURIzQMk-aA9"
      },
      "outputs": [],
      "source": [
        "# Google colab\n",
        "\n",
        "from google.colab import data_table\n",
        "from google.colab import files\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# hyperopt\n",
        "\n",
        "import hyperopt\n",
        "from hyperopt.pyll import as_apply\n",
        "from hyperopt import tpe, hp\n",
        "import hpsklearn\n",
        "from hpsklearn import HyperoptEstimator, random_forest_classifier, extra_trees_classifier, bagging_classifier, \\\n",
        "  ada_boost_classifier, gradient_boosting_classifier, hist_gradient_boosting_classifier, bernoulli_nb, \\\n",
        "  categorical_nb, complement_nb, gaussian_nb, multinomial_nb, sgd_classifier, sgd_one_class_svm, \\\n",
        "  ridge_classifier, ridge_classifier_cv, passive_aggressive_classifier, perceptron, \\\n",
        "  dummy_classifier, gaussian_process_classifier, mlp_classifier, linear_svc, nu_svc, svc, \\\n",
        "  decision_tree_classifier, extra_tree_classifier, label_propagation, label_spreading, elliptic_envelope, \\\n",
        "  linear_discriminant_analysis, quadratic_discriminant_analysis, bayesian_gaussian_mixture, gaussian_mixture, \\\n",
        "  k_neighbors_classifier, radius_neighbors_classifier, nearest_centroid, \\\n",
        "  xgboost_classification, lightgbm_classification, mlp_regressor\n",
        "\n",
        "from hpsklearn.components import all_classifiers, all_preprocessing, any_classifier, any_preprocessing, \\\n",
        "any_regressor, all_regressors\n",
        "\n",
        "# Hyperparameter optimization\n",
        "\n",
        "import skopt\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "# system\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "# data analysis and plotting\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from math import sqrt\n",
        "\n",
        "from scipy.stats import zscore, shapiro\n",
        "from random import randint\n",
        "\n",
        "# data processing and model validation\n",
        "\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, Normalizer, MinMaxScaler\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, \\\n",
        "accuracy_score, classification_report, log_loss, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold, KFold, \\\n",
        "LeaveOneOut, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold, StratifiedKFold\n",
        "\n",
        "# classification libraries\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel, Matern, RationalQuadratic\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, \\\n",
        "ExtraTreesRegressor, ExtraTreesClassifier, RandomForestRegressor\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "#from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "#import lightgbm as lgb\n",
        "\n",
        "# Importing imputation libs\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "\n",
        "# Missing data models\n",
        "\n",
        "from itertools import combinations\n",
        "from joblib import parallel_backend\n",
        "\n",
        "# Export models into pickle\n",
        "import pickle\n",
        "\n",
        "# Tensorflow \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "# import scikeras\n",
        "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "\n",
        "\n",
        "# Various parameter settings\n",
        "\n",
        "#%matplotlib inline\n",
        "\n",
        "\n",
        "# To change scientific numbers to float\n",
        "#np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "# Increases the size of sns plots\n",
        "#sns.set(rc={'figure.figsize':(12,10)})\n",
        "\n",
        "# import sys\n",
        "\n",
        "# Displaying all the rows/columns in a data set (the default option is not to show them)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuRvt9Vv-aA_"
      },
      "source": [
        "# **Importing and preparing the data for the analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhW6bRHYBJ4P"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjiE8KVhBWRU"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv(io.BytesIO(uploaded['age_dataset.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UPg9uJF-aBA"
      },
      "outputs": [],
      "source": [
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5BVGEOF-aBB"
      },
      "outputs": [],
      "source": [
        "df = raw_data.iloc[:,[2, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 38, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QtP5_h2-aBC"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(df.values[3:], columns=df.iloc[2])\n",
        "\n",
        "df = df.astype(int)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR8_DpUa-aBD"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GS2-YI6-aBH"
      },
      "outputs": [],
      "source": [
        "# Add a new target vector called age groups\n",
        "\n",
        "df['Age_groups'] = pd.cut(df['Age'], bins=[10,35,50,100], labels=False)\n",
        "\n",
        "df = df.astype(int)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xRImeyg-aBJ"
      },
      "outputs": [],
      "source": [
        "# View the data as a table\n",
        "\n",
        "data_table.DataTable(df, include_index=False, num_rows_per_page=10, max_columns=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables dictionary**"
      ],
      "metadata": {
        "id": "B8E4yJm_Gg69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables_sets = {\n",
        "    \"Suchey Brooks 1990\": [\n",
        "        'Right Phase Suchey'\n",
        "        ],\n",
        "    \"Meindl and Lovejoy\": [\n",
        "        'Right 1-midlamdoid',\n",
        "        '2-lambda', \n",
        "        '3-obelion', \n",
        "        '4-anterior sagital',\n",
        "        '5-bregma', \n",
        "        'Right 6-midcoronal', \n",
        "        'Right 7-pterion',\n",
        "        'Right 8-sphenofrontal', \n",
        "        'Right 9-inferior sphenotemporal', \n",
        "        'Right 10-superior sphenotemporal'\n",
        "        ],\n",
        "    \"Lovejoy et al\": [\n",
        "        \"Right Phase\"\n",
        "    ],\n",
        "    \"Buckberry and Chamberlain\": [\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes'\n",
        "        ],\n",
        "    \"Suchey Brooks 1990 and Lovejoy et al\": [\n",
        "        'Right Phase Suchey',\n",
        "        'Right Phase' \n",
        "    ],\n",
        "    \"Suchey Brooks 1990 and Buckberry Chamberlain\": [\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes',\n",
        "        'Right Phase Suchey'\n",
        "    ],\n",
        "    \"All\": [\n",
        "        'Right Phase Suchey',\n",
        "        'Right 1-midlamdoid',\n",
        "        '2-lambda', \n",
        "        '3-obelion', \n",
        "        '4-anterior sagital',\n",
        "        '5-bregma', \n",
        "        'Right 6-midcoronal', \n",
        "        'Right 7-pterion',\n",
        "        'Right 8-sphenofrontal', \n",
        "        'Right 9-inferior sphenotemporal', \n",
        "        'Right 10-superior sphenotemporal',\n",
        "        \"Right Phase\",\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes'\n",
        "    ]\n",
        "} \n"
      ],
      "metadata": {
        "id": "UfSIif6wM9CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification (sklearn)** "
      ],
      "metadata": {
        "id": "mpVJkJpvGGuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex specific**"
      ],
      "metadata": {
        "id": "dz9m-YDHDarK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Change df[df[\"sex\"]==2] to df[df[\"sex\"]==1] for male\n",
        "\n",
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  model = HyperoptEstimator(classifier=any_classifier('classifier'), preprocessing=any_preprocessing('preprocessing'), \\\n",
        "                          algo=tpe.suggest, max_evals=100, trial_timeout=100, continuous_loss_fn=False)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # Run a LOOCV for model\n",
        "\n",
        "  result_loocv = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=LeaveOneOut(), error_score='raise')\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['classification_right_women_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['classification_right_women_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"Accuracy: {}\\n\".format(acc))\n",
        "    infofile.write(\"Confusion matrix: \\n{}\\n\".format(cnfm))\n",
        "    infofile.write(\"LOOCV accuracy: {}\\n\".format(result_loocv.mean()))\n"
      ],
      "metadata": {
        "id": "iaZSzTzBt7SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classification_right_women_Suchey_Brooks_1990.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "jnRAzV8I4ogz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex blind**"
      ],
      "metadata": {
        "id": "Iwdr1S2DX-1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df \n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  model = HyperoptEstimator(classifier=any_classifier('classifier'), preprocessing=any_preprocessing('pre'), \\\n",
        "                          algo=tpe.suggest, max_evals=100, trial_timeout=100)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # Run a LOOCV for model\n",
        "\n",
        "  result_loocv = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=LeaveOneOut(), error_score='raise')\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['classification_right_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['classification_right_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"Accuracy: {}\\n\".format(acc))\n",
        "    infofile.write(\"Confusion matrix: \\n{}\\n\".format(cnfm))\n",
        "    infofile.write(\"LOOCV accuracy: {}\\n\".format(result_loocv.mean()))\n",
        "\n"
      ],
      "metadata": {
        "id": "KcgEl-I2FSI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classification_right_Suchey_Brooks_1990_and_Buckberry_Chamberlain.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "58HGvCq_HsfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classification_right_Suchey_Brooks_1990_and_Buckberry_Chamberlain.dat', 'rb') as f:\n",
        "  model = pickle.load(f)\n",
        "  y_pred = model.predict_proba(X_test)\n",
        "  print(y_pred)"
      ],
      "metadata": {
        "id": "oEMBCzIkdw7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression (sklearn)**"
      ],
      "metadata": {
        "id": "TXVJvjEpy3h0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex specific**"
      ],
      "metadata": {
        "id": "prWg7okJqfHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "\n",
        "  print(\"key: \", key)\n",
        "  print(\"value: \", value)\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "  model = HyperoptEstimator(regressor=any_regressor('regressor'), preprocessing=any_preprocessing('pre'), \\\n",
        "                          algo=tpe.suggest, max_evals=100, loss_fn=mean_absolute_error, \\\n",
        "                          trial_timeout=100,continuous_loss_fn=False, verbose=True)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "\n",
        "  #predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "\n",
        "  # metrics\n",
        "\n",
        "  #acc = model.score(X_test, y_test) # R^2 on test set\n",
        "  r2_test = r2_score(y_test, y_pred) # R^2 on test set using sklearn (same as above)\n",
        "  r2_train = r2_score(y_train, y_pred_train) # R^2 on training set\n",
        "  rmse = mean_squared_error(y_pred, y_test, squared=False) # root mean squared error\n",
        "  mae = mean_absolute_error(y_pred, y_test) # mean absolute error\n",
        "\n",
        "  # train model again on the full dataset using best estimator and hyperparamaters\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  plt.plot(pipe.predict(X_test),'ro')\n",
        "  plt.plot(y_test,'b*')\n",
        "  plt.title(key)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  # save model and model information  \n",
        "\n",
        "  filename = ''.join(['regression_right_women_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['regression_right_women_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"R **2 = {} (test), R**2 = {} (train)\\n\".format(r2_test, r2_train))\n",
        "    infofile.write(\"RMSE = {}\\n\".format(rmse))\n",
        "    infofile.write(\"MAE = {}\\n\".format(mae))\n",
        "\n"
      ],
      "metadata": {
        "id": "GbmBCg0Hzs5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('regression_right_women_All.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "rzvDNu3bfcmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('regression_right_women_All.dat', 'rb') as f:\n",
        "  pickle.load(f).predict(X_test)"
      ],
      "metadata": {
        "id": "HuISNsoLfpPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('regression_right_women_All.dat', 'rb') as f:\n",
        "  plt.plot(pickle.load().predict(X_test),'ro')\n",
        "  plt.plot(y_test,'b*')"
      ],
      "metadata": {
        "id": "X913zTok90a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate Bias-Inaccuracy**"
      ],
      "metadata": {
        "id": "li5R0BgSRKH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dff = df[df['sex']==2]\n",
        "y = dff['Age'].values\n",
        "\n",
        "output_list = []\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "\n",
        "    print(\"key: \", key)\n",
        "    #print(\"value: \", value)\n",
        "\n",
        "    X = dff[value].values\n",
        "\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "    # model\n",
        "\n",
        "    filename = ''.join(['regression_right_women_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  \n",
        "    with open(filename, \"rb\") as modelfile:\n",
        "        model = pickle.load(modelfile)\n",
        "\n",
        "        #predictions\n",
        "        y_pred = model.predict(X)\n",
        "        #print((y_pred-y))\n",
        "        bias = np.sum((y_pred-y))/len(X)\n",
        "        inaccuracy = np.sum(np.absolute(y_pred-y))/len(X)\n",
        "        \n",
        "        output_dict = {'key': key, 'bias': bias, 'inaccuracy': inaccuracy}\n",
        "        output_list.append(output_dict)\n",
        "\n",
        "df_bias_inaccuracy = pd.DataFrame(output_list)\n",
        "\n",
        "df_bias_inaccuracy\n"
      ],
      "metadata": {
        "id": "s-wpkYvZbvvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex blind**"
      ],
      "metadata": {
        "id": "fF_sCgwzuurr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df \n",
        "y = dff['Age'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "  model = HyperoptEstimator(\n",
        "      regressor=any_regressor('regressor'), \n",
        "      preprocessing=any_preprocessing('pre'), \n",
        "      algo=tpe.suggest, \n",
        "      max_evals=100, \n",
        "      trial_timeout=100\n",
        "      )\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "\n",
        "  #predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "\n",
        "  # metrics\n",
        "\n",
        "  #acc = model.score(X_test, y_test) # R^2 on test set\n",
        "  r2_test = r2_score(y_test, y_pred) # R^2 on test set using sklearn (same as above)\n",
        "  r2_train = r2_score(y_train, y_pred_train) # R^2 on training set\n",
        "  rmse = mean_squared_error(y_pred, y_test, squared=False) # root mean squared error\n",
        "  mae = mean_absolute_error(y_pred, y_test) # mean absolute error\n",
        "\n",
        "  # train model again on the full dataset using best estimator and hyperparamaters\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # plot results\n",
        "\n",
        "  plt.plot(pipe.predict(X_test),'ro')\n",
        "  plt.plot(y_test,'b*')\n",
        "  plt.title(key)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  # save model and model information  \n",
        "\n",
        "  filename = ''.join(['regression_right_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['regression_right_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"R **2 = {} (test), R**2 = {} (train)\\n\".format(r2_test, r2_train))\n",
        "    infofile.write(\"RMSE = {}\\n\".format(rmse))\n",
        "    infofile.write(\"MAE = {}\\n\".format(mae))\n"
      ],
      "metadata": {
        "id": "O8FkmnaQuw9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Networks**"
      ],
      "metadata": {
        "id": "8uDLUTRI_EpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification (MLPClassifier)**"
      ],
      "metadata": {
        "id": "F2qo0_tImgNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex specific**"
      ],
      "metadata": {
        "id": "w-d4l6Waq_Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  \n",
        "  X = dff[value].values\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  model = HyperoptEstimator(classifier=mlp_classifier(\"mlp_classifier\", \\\n",
        "                          hidden_layer_sizes=hp.choice('hidden_layer_sizes', [(10,), (20,), (100,), (10, 10), (100, 100)])), \\\n",
        "                          preprocessing=any_preprocessing(\"preprocessing\"), \\\n",
        "                          algo=tpe.suggest, max_evals=100, trial_timeout=100)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # Run a 20-fold CV model\n",
        "  seed = 7\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  kFold = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
        "\n",
        "  result_loocv = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=kFold, error_score='raise')\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['ann_classification_right_women_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['ann_classification_right_women_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"Accuracy: {}\\n\".format(acc))\n",
        "    infofile.write(\"Confusion matrix: \\n{}\\n\".format(cnfm))\n",
        "    infofile.write(\"20-fold accuracy: {}\\n\".format(result_loocv.mean()))\n",
        "\n"
      ],
      "metadata": {
        "id": "zsOkJ9Xwq7xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex blind**"
      ],
      "metadata": {
        "id": "gNGZA86Pck3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df \n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  \n",
        "  X = dff[value].values\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  model = HyperoptEstimator(classifier=mlp_classifier(\"mlp_classifier\", \\\n",
        "                          hidden_layer_sizes=hp.choice('hidden_layer_sizes', [(10,), (20,), (100,), (10, 10), (100, 100)])), \\\n",
        "                          preprocessing=any_preprocessing(\"preprocessing\"), \\\n",
        "                          algo=tpe.suggest, max_evals=100, trial_timeout=100)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # Run a 20-fold CV model\n",
        "  seed = 7\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  kFold = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)\n",
        "\n",
        "  result_loocv = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=kFold, error_score='raise')\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['ann_classification_right_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['ann_classification_right_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"Accuracy: {}\\n\".format(acc))\n",
        "    infofile.write(\"Confusion matrix: \\n{}\\n\".format(cnfm))\n",
        "    infofile.write(\"20-fold accuracy: {}\\n\".format(result_loocv.mean()))\n",
        "\n"
      ],
      "metadata": {
        "id": "cV5zQKoYmdbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ann_classification_right_Suchey_Brooks_1990.txt', 'r') as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "id": "4u5iXsRrDy6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression (MLPRegressor)**"
      ],
      "metadata": {
        "id": "wU-UBJoCfhC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex specific**"
      ],
      "metadata": {
        "id": "LaTcw1fWuL1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age'].values \n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  \n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        " \n",
        "  layers = hp.choice('layers', np.arange(10, 15))\n",
        "  solver = hp.choice('sol', ['lbfgs', \"lbfgs\", \"sgd\", \"adam\"])\n",
        "  iter = hp.choice('iter', [1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000])\n",
        "  alpha = hp.choice('alph', 10.0 ** -np.arange(1, 10))\n",
        "  random_state=hp.choice('rand', [0,1,2,3,4,5,6,7,8,9])\n",
        "\n",
        "  space = as_apply({\n",
        "      \"classifier\": None,\n",
        "      \"regressor\": mlp_regressor('mlp', \n",
        "                                hidden_layer_sizes = layers, \n",
        "                                solver=solver,\n",
        "                                max_iter=iter,\n",
        "                                alpha=alpha,\n",
        "                                random_state=random_state,\n",
        "                                batch_size=\"auto\",\n",
        "                                learning_rate=\"constant\",\n",
        "                                learning_rate_init=0.001,\n",
        "                                power_t=0.5,\n",
        "                                shuffle=True,\n",
        "                                tol=1e-4,\n",
        "                                verbose=False,\n",
        "                                warm_start=False,\n",
        "                                momentum=0.9,\n",
        "                                nesterovs_momentum=True,\n",
        "                                early_stopping=False,\n",
        "                                validation_fraction=0.1,\n",
        "                                beta_1=0.9,\n",
        "                                beta_2=0.999,\n",
        "                                epsilon=1e-8,\n",
        "                                n_iter_no_change=10,\n",
        "                                max_fun=15000\n",
        "                                ),\n",
        "      \"preprocessing\": any_preprocessing(\"pre\"),\n",
        "      \"ex_preprocs\": []})\n",
        "  \n",
        "\n",
        "  model = HyperoptEstimator(space=space, algo=tpe.suggest, max_evals=100, trial_timeout=100, verbose=True, loss_fn=mean_absolute_error)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "\n",
        "  #predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "\n",
        "  # metrics\n",
        "\n",
        "  #acc = model.score(X_test, y_test) # R^2 on test set\n",
        "  r2_test = r2_score(y_test, y_pred) # R^2 on test set using sklearn (same as above)\n",
        "  r2_train = r2_score(y_train, y_pred_train) # R^2 on training set\n",
        "  rmse = mean_squared_error(y_pred, y_test, squared=False) # root mean squared error\n",
        "  mae = mean_absolute_error(y_pred, y_test) # mean absolute error\n",
        "\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # plot results\n",
        "\n",
        "  plt.plot(pipe.predict(X_test),'ro')\n",
        "  plt.plot(y_test,'b*')\n",
        "  plt.title(key)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['ann_regression_right_women_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['ann_regression_right_women_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    #infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"R **2 = {} (test), R**2 = {} (train)\\n\".format(r2_test, r2_train))\n",
        "    infofile.write(\"RMSE = {}\\n\".format(rmse))\n",
        "    infofile.write(\"MAE = {}\\n\".format(mae))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZO0AnJWeuJ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sex blind**"
      ],
      "metadata": {
        "id": "X2iqFYFvc71h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df\n",
        "y = dff['Age'].values \n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "  \n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "\n",
        "  # parameters = {\n",
        "  #     'solver': ['lbfgs', \"lbfgs\", \"sgd\", \"adam\"], \n",
        "  #     'max_iter': [1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000], \n",
        "  #     'alpha': 10.0 ** -np.arange(1, 10), \n",
        "  #     'hidden_layer_sizes':np.arange(10, 15), \n",
        "  #     'random_state':[0,1,2,3,4,5,6,7,8,9]\n",
        "  #     }\n",
        "\n",
        " \n",
        "  layers = hp.choice('layers', np.arange(10, 15))\n",
        "  solver = hp.choice('sol', ['lbfgs', \"lbfgs\", \"sgd\", \"adam\"])\n",
        "  iter = hp.choice('iter', [1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000])\n",
        "  alpha = hp.choice('alph', 10.0 ** -np.arange(1, 10))\n",
        "  random_state=hp.choice('rand', [0,1,2,3,4,5,6,7,8,9])\n",
        "\n",
        "  space = as_apply({\n",
        "      \"classifier\": None,\n",
        "      \"regressor\": mlp_regressor('mlp', \n",
        "                                hidden_layer_sizes = layers, \n",
        "                                solver=solver,\n",
        "                                max_iter=iter,\n",
        "                                alpha=alpha,\n",
        "                                random_state=random_state,\n",
        "                                batch_size=\"auto\",\n",
        "                                learning_rate=\"constant\",\n",
        "                                learning_rate_init=0.001,\n",
        "                                power_t=0.5,\n",
        "                                shuffle=True,\n",
        "                                tol=1e-4,\n",
        "                                verbose=False,\n",
        "                                warm_start=False,\n",
        "                                momentum=0.9,\n",
        "                                nesterovs_momentum=True,\n",
        "                                early_stopping=False,\n",
        "                                validation_fraction=0.1,\n",
        "                                beta_1=0.9,\n",
        "                                beta_2=0.999,\n",
        "                                epsilon=1e-8,\n",
        "                                n_iter_no_change=10,\n",
        "                                max_fun=15000\n",
        "                                ),\n",
        "      \"preprocessing\": any_preprocessing(\"pre\"),\n",
        "      \"ex_preprocs\": []})\n",
        "  \n",
        "\n",
        "  model = HyperoptEstimator(space=space, algo=tpe.suggest, max_evals=100, trial_timeout=100, verbose=True, loss_fn=mean_absolute_error)\n",
        "  \n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  #print(model.best_params_)\n",
        "  \n",
        "  #model.fit(X_train, y_train)\n",
        "\n",
        "  # summarize performance\n",
        "\n",
        "  #predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "\n",
        "  # metrics\n",
        "\n",
        "  #acc = model.score(X_test, y_test) # R^2 on test set\n",
        "  r2_test = r2_score(y_test, y_pred) # R^2 on test set using sklearn (same as above)\n",
        "  r2_train = r2_score(y_train, y_pred_train) # R^2 on training set\n",
        "  rmse = mean_squared_error(y_pred, y_test, squared=False) # root mean squared error\n",
        "  mae = mean_absolute_error(y_pred, y_test) # mean absolute error\n",
        "\n",
        "\n",
        "  # retrain on full dataset using best parameters\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  # plot results\n",
        "\n",
        "  plt.plot(pipe.predict(X_test),'ro')\n",
        "  plt.plot(y_test,'b*')\n",
        "  plt.title(key)\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  # save information and model\n",
        "\n",
        "  filename = ''.join(['ann_regression_right_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  infofilename = ''.join(['ann_regression_right_', key.replace(\" \",\"_\"), \".txt\"])\n",
        "\n",
        "  with open(filename, \"wb\") as modelfile:\n",
        "    pickle.dump(pipe, modelfile)\n",
        "\n",
        "  with open(infofilename, \"w\") as infofile:\n",
        "    infofile.write(\"---------------------------------\\n\")\n",
        "    infofile.write(key + '\\n')\n",
        "    infofile.write(\"Dataset size: {} {}\\n\".format(len(X), len(y)))\n",
        "    #infofile.write(\"Best classifier: {}\\n\".format(model.best_model()))\n",
        "    infofile.write(\"R **2 = {} (test), R**2 = {} (train)\\n\".format(r2_test, r2_train))\n",
        "    infofile.write(\"RMSE = {}\\n\".format(rmse))\n",
        "    infofile.write(\"MAE = {}\\n\".format(mae))\n",
        "\n"
      ],
      "metadata": {
        "id": "ubYrEOTmBw5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate bias**"
      ],
      "metadata": {
        "id": "twHTDV4mgfIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dff = df#[df['sex']==2]\n",
        "y = dff['Age'].values\n",
        "\n",
        "output_list = []\n",
        "\n",
        "for key, value in independent_variables_sets.items():\n",
        "\n",
        "    X = dff[value].values\n",
        "\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "    # model\n",
        "\n",
        "    filename = ''.join(['ann_regression_right_', key.replace(\" \",\"_\"), \".dat\"])\n",
        "  \n",
        "    with open(filename, \"rb\") as modelfile:\n",
        "        model = pickle.load(modelfile)\n",
        "\n",
        "        #predictions\n",
        "        y_pred = model.predict(X)\n",
        "        #print((y_pred-y))\n",
        "        bias = np.sum((y_pred-y))/len(X)\n",
        "        inaccuracy = np.sum(np.absolute(y_pred-y))/len(X)\n",
        "        \n",
        "        output_dict = {'key': key, 'bias': bias, 'inaccuracy': inaccuracy}\n",
        "        output_list.append(output_dict)\n",
        "\n",
        "df_bias_inaccuracy = pd.DataFrame(output_list)\n",
        "\n",
        "df_bias_inaccuracy\n"
      ],
      "metadata": {
        "id": "E7Ya8CzlgexP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zip results and download**"
      ],
      "metadata": {
        "id": "f_J_ANaWdDFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results.zip /content/*"
      ],
      "metadata": {
        "id": "i18Rq4TnJID_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/results.zip\")\n"
      ],
      "metadata": {
        "id": "PaalBHjjJ7rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtS44oswuCmj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}